# 操作系统导论

- 操作系统是一类将物理资源转换为更易于使用的虚拟形式，并提供了接口给应用程序访问资源，操作系统的作用就是管理这些资源。

## 虚拟化CPU

- 定义：
  
  在硬件的帮助下，操作系统提供了一种能同时运行多个程序的假象，单个CPU转化为看似无限数量的CPU，这就是虚拟化CPU

### 时分共享CPU技术

- 本质就是分时复用，不同时间下切换不同的进程（进程的状态有**运行、就绪、阻塞**）

### 系统调用

- 由操作系统提供的接口进入内核态，有trap table决定硬件在遇到那些情况就会执行什么异常和中断函数（类似stm32的中断

### 进程调度

#### 底层机制是进行上下文切换

#### 上层策略（调度策略）

- 调度指标：
  
  - 周转时间：任务完成时间减去任务到达时间
  - 响应时间：任务首次运行减去任务到达时间

- 调度策略：
  
  1. 先进先出（FIFO）
     
     弊端：过长的任务排在前面会导致后面的任务的响应性能很差
  
  2. 最短任务优先（SJF）
     
     弊端：在任务不是同时到达，一样存在和上面的响应性能很差的情况
  
  3. 最短完成时间优先（STCF）
     
     优先：优化了最短任务优先出现的问题，只要是任务剩余的运行时间长就排到后面运行
  
  4. 轮转/时间片（RR）
     
     响应时间受时间片长短的影响，同时也影响着周转时间，且RR的周转时间是最差的，因为周转时间关注是完成时间
  
  **总结：SJF、STCF优化周转时间，但响应时间不利，RR优化响应时间，但对周转时间不利。**
  
  ​        **运行最短的工作，优化周转时间；交替运行所有任务，优化响应时间。**
  
  5. 利用最近的历史预测未来的多级反馈队列（MLFQ：multi-level Feedback Queue）
     
     思想就是如果任务很快完成就会保持高优先级，如果运行时间长就会被降低优先级，但同时任务都是在轮转的，调度根据优先级进行调度
     
     - 任务一开始都具有一样高的优先级，如果任务在一层优先级中使用完其时间配额就降低任务优先级

- 周期性提高所有任务的优先级
  
  **MLFQ规则：**

- A优先级高于B，优先运行A

- A优先级等于B，轮转运行AB

- 初始所有任务都是最高优先级

- 一旦任务用完了在某一层优先级的时间配额还没主动放弃CPU，就会降低任务的优先级

- 经过一个周期S就将所有任务重置为最高优先级，防止饿死低优先级的任务。
  
  6. 比例份额调度
     
     - 利用随机性进行调度，但需要工作执行的时间片非常多时才能得到期望值
     - 当然也存在一个问题，比例分配问题，因为类似蒙特卡罗算法，各个任务的比例分配是策略的重点
  
  7. 步长调度（stride scheduling）：在一个调度周期后做到完全正确调度
     
     根据比列额度为任务分配步数，步数和比例成反比，步数少的会优先执行，执行一次步数会加倍，因为多个任务的步数是公倍数的关系，直到计数步数到最大的步数时会进行重置所以任务的步数，实现了一个根据步数决定一个周期内某个任务运行的次数。

### 多核任务调度策略

- 考虑缓存的亲和度
1. SQMS：Single Queue MultiProcessor Scheduling
   
   每个CPU都从单队列中领任务运行，但这有一个很明显的弊端，每个任务有自己的一个数据需要加载，这样的任务切换开销过大，扩展性也不好，任务之间的同步开销也大（因为单个队列，这个队列是一个共享数据，需要实现互斥访问，降低了CPU的效率）

2. MQMS：Multi-Queue MultiProcessor Scheduling
   
   每个CPU都有自己的调度队列，可以很好的利用缓存，具有缓存亲和度，但仍然存在每个CPU工作负载不均和任务调度的问题（多核任务调度比较麻烦）
   
   为了解决工作负载不均的问题，可以采取迁移技术，就是让一个任务从工作载荷高的迁移到工作载荷低的CPU上，获知其他CPU工作载荷是通过不定期查看其他CPU队列，对比和自己的工作载荷，进而窃取一个或多个任务，实现CPU负载均衡。

3. Linux多处理器调度程序：
   
   - O(1)调度程序：基于优先级，类似MLFQ(Multi-Level Feedback Queue)
- CFS：完全公平调度程序
  
  基于比例调度，但采用了更复杂的方案（最早最适合虚拟截止时间优先算法EEVEF）

- BF调度程序

## 虚拟化内存

- 每个进程都有自己的地址空间，这是虚拟内存，是有操作系统进行的内存虚拟化，对物理空间进行分配，物理内存由操作系统管理。

### 一些概念

- 用户程序生成的每个地址都是虚拟地址，在一些硬件（MMU）的帮助下操作系统会将虚拟地址编程真实的物理地址，从而找到对应的信息。
- 将多个程序同时驻留在内存，是任务切换的开销降低，但同时也存在保护的问题

### 地址空间

- 物理内存的抽象
- 内存空间：代码段、静态数据段(bss)、可读可写数据段、栈区、堆区、

### 并发

- 并发引发的问题
  
  并发，多进程和多线程并发中存在着同步的问题（原子操作，互斥锁，信号、信号量），需要进行协调和同步，互斥访问共享资源

### 空间管理

- 解决的关键问题：
  1. 内存引用开销大（映射信息存储在物理内存中，转换时需要额外读一次内存获得转换信息）
  2. 占用内存太多

---

解决关键问题1

- 分页
  
  - 但是分页分成了不同长度时存在空间碎片化的问题，因此分成固定长度的分片
  
  - 分页的优点：
    
    - 增加了灵活性，操作系统能够高效地提供地址空间的抽象
    - 与分段相比不会产生外部碎片化，支持稀疏虚拟地址空间（同一进程虚拟地址可以映射到不连续的物理地址）
  
  - 页表：操作系统为每个进程保存的一个数据结构，用于地址映射
  
  - 地址转换：
    
    - 页表就是用于将虚拟地址映射到物理地址（物理帧号）
    
    - 虚拟页面号（VPN）+页内偏移量（offset）
    
    - 在没有借助任何MMU硬件存储，需要消耗大量的内存来存储每个进程的页表
    
    - 采用数组作为线性页表，操作系统通过虚拟页号去检索数组，并在该索引处查找页表项（PTE）
      
      页表项（Page Table Event）用于保存物理地址转换和其他有用的数据（比如存在有效位、访问位、保护位、存在位、脏位）
      
      tip：位于操作系统导论P135

- 分页：快速地址转换（TLB）
  
  - 地址转换缓存（address-translation cache）
  - 原理：
  
  每次访问内存，硬件先检查TLB，查看其中是否有期望的转换映射，如果有就很快转换完成，不用访问页表，带来了巨大的性能提升。（TLB命中是命中虚拟页，此后该页内的访问都可以命中）
  
  - 硬件和软件管理TLB
    
    - 硬件管理的TLB和硬件处理TLB未命中，当未命中时硬件会遍历页表，并更新TLB
    
    - 软件管理TLB，未命中时抛出异常，会进入内核态，跳转到陷阱处理程序，程序负责查找页表完成映射并更新TLB。**进入这种陷阱与系统调用的返回不太一样，因为在更新完TLB后需要返回访问内存的地方，而不是继续往下执行，返回后访问内存成功（因为陷阱处理程序已经更新了TLB）**
      
      软件管理TLB优势是灵活，操作系统可以以任意数据结构来实现页表，无需改变硬件，将处理未命中的任务交给了软件，硬件不需要做太多工作，只需抛出异常即可。
    
    - 上下文切换时对TLB的处理，因为是根据虚拟页面进行命中的，而不同进程的虚拟页面都是0-N，重复会**导致一对多的映射，加入了进程ID(PID)进行区分**，实现了唯一映射
      
      存在不同进程的不同虚拟页面指向同一物理页面，比如共享代码时，共享的代码存储在一个物理页面。

- TLB替换策略
  
  - 目标就是提高命中率，改进性能
    - 替换最少用的
    - 随机替换

- MIPS TLB 提供用来更新TLB的指令
  
  - TLBP：查找指定的转换映射是否在TLB中
  - TLBR：用于将TLB中的内容读取到寄存器中
  - TLBWI：替换指定的TLB项
  - TLBWR：随机替换一个TLB

---

解决关键问题2

- 更大的页，减少页的数目，存储量随页大小倍数减小也跟着倍数减小
- 使用分段+分页的方法（每一段需要硬件支持存储基地址和界限）
  - 分段需要有两个位来区别是那一段，和界限寄存器来指示有多少有效页（映射前使用了虚拟地址中的多少），减少了内部碎片化。
- 多级页表
  - 引入了页表项对已经分配的页表进行记录，分配表示有效，驻留在内存中，减少了内存的开销，开销与正在使用的地址空间内存量成正比，同时也支持稀疏的地址空间
  - 三级页表：（得到一级页表项找二级页目录）页目录地址+页目录索引=（得到二级页表项找页表）页表地址+页表索引=（页表项中得到信息，配合偏移量）页地址+页内偏移=物理地址
  - 反向页表：表刘一个页表，页表中的页表项代表每个物理页，页表项存储哪个进程使用此页，以及进程将哪个虚拟页映射到此页
- 将页表交换到磁盘
  - 当内存压力较大时，将部分页表交换到磁盘上。

---------

空间管理是内存和命中率（转换时间）的一个折中，时空权衡。（软件管理TLB赋予虚拟内存更灵活的操作）

### 超越物理内存

- 交换空间
  
  将一部分页表交换到磁盘上，在需要访问这部分内存时会出现**页错误**,硬件会触发这个异常，转而由操作系统进行处理，进行页错误处理程序，在错误处理程序中，将页交换到内存中（通过页表项查找地址），然后更新页表项，再重试操作在TLB中找到对应的映射关系，完成物理地址的转换，获取所需的数据和指令
  
  **页错误控制流算法：**
  
  由硬件-》软件
  
  - 硬件
    - 根据VPN看是否有TLB匹配
    - 匹配成功
      - 有效，直接得到地址转换
      - 无效，硬件产生一个异常
    - 匹配失败
      - 无效，硬件产生异常
      - 页存在内存中，可以找到地址转换的页映射关系
      - 页存在于磁盘中，硬件产生异常，由软件处理页错误
  - 软件
    - 查找是否有空闲页，没有的话通知后台分页线程按需释放页，释放完毕后进行下面的步骤
    - 找到空闲的物理内存页
    - 读磁盘（sleep and waiting for IO）
    - 修改页目录项
    - 重新运行指令

- 策略：同样的将物理内存页看做缓存，将磁盘空间看做内存空间，好的策略就类似提高TLB命中率
  
  选择合适的策略可以提高内存也存在和命中的概率
  
  - FIFO：不考虑页面的重要性，硬性的先进的页面先被踢出去
  
  - 随机：取决于运气
  
  - 利用历史数据
    
    - 最不经常使用（LFU）
    
    - 最近最少使用（LRU）
    
    - 实现了一种利用历史信息的策略：硬件增加一个使用位，用于表示该页是使用过的
      
      脏位，用于表示该页是被修改了的，踢出该页需要将其写入磁盘，如果原封不动，那磁盘上本身就存着，就只需要修改状态即可
  
  - 抖动：内存超额请求，反复踢出和载入，某些版本的Linux会运行一个内存不足的守护进程进行处理

- VMS操作系统
  
  - 内存硬件管理（32位虚拟地址空间，23位VPN，高2位用于分段，其他用于多级页表，剩下9位用于偏移量）
  
  - 真实地址空间是不会从0页开始的，0页被标记为不可访问页（无效，会引发异常），以便检测空指针，因为解引用一个空指针会导致TLB未命中，查询页表发现VPN0为无效。
  
  - 操作系统不希望用户程序读取或者写入操作系统的数据和代码，硬件上支持页面不同级别的保护。
  
  - 页表项中包含以下位：一个有效位，一个保护字段（4位），一个脏位，OS保留字段（5位），最后是一个物理帧号码（PFN）
  
  - 脏位是用于标记哪些页是被修改过的，在后面被踢出物理内存时需要重新写入磁盘（IO），脏页可以聚集一起写入，防止写入量过小，性能过低。
  
  - 没有引用位，使用保护位进行代替，这样就不会踢出已修改的页了。
  
  - 虚拟内存技巧：
    
    - 按需置零，使用了一个页，需要将其置零，表示已经在使用（操作系统在页表中放入一个标记页不可访问条目），防止其他进程使用该页
    
    - 写时复制：操作系统需要将一个页面从一个地址复制到另一个地址时，不会马上实际复制，而是将其映射到目标地址空间，两个都标记为只读，如果其中一个尝试写入，会陷入操作系统并因为此页面是一个写时复制页面，因此会分配一个新页进行映射
      
      任何共享库都可以通过写时复制映射到许多进程的地址空间。
      
      fork()进行写时复制可以避免不必要的复制，因为大部分fork()后会调用exec()进行覆盖，先映射后惰性进行覆盖提高性能。

### 内存虚拟化总结

- 程序运行时，我们所看到的所有地址都是虚拟地址，真实的物理地址被操作系统隐藏了，TLB为系统提供了地址转换的硬件缓存，TLB使虚拟内存成为了可能
- 混合页表或多级页表可以节省内存空间
- 页替换使得可以超越物理内存的限制（交换策略使得对性能的影响降低，像脏位、聚集都是为了提高性能）
- 提高性能的最终策略是购买更大的内存，以至于不用频繁地交换到磁盘中。

## 并发

### 线程

- 线程之间共享地址空间，每个线程有TCB保存每个线程的状态，每个线程都有独立的线程栈空间。

- 多个线程运行出现的问题：共享数据
  
  - 不可控的调度导致的对数据的同时访问，对共享数据的修改和访问和预期不一致，其原因就是多个线程导致的对数据访问的竞争，这段代码叫做临界区，临界区是访问共享数据的代码片段。
    - 解决的方法是使用锁实现对共享数据的互斥访问，同一时刻只能由一个线程访问此数据。

- tip：不要返回局部指针，因为被释放后其值为未知。

- 锁
  
  - 用于互斥访问
    
    - 创建锁并初始化
      
      ```c
      pthread_mutex_init();
      ```
    
    - 获取锁
      
      ```c
      pthread_mutex_lock();
      pthread_mutex_trylock();
      pthread_mutex_timelock();//允许阻塞在锁上的最长时间
      ```
    
    - 释放锁
      
      ```c
      pthread_mutex_destroy();
      ```

- 条件变量
  
  - ```c
    pthread_cond_wait()
    pthread_cond_signal()
    ```
    
    ​

- 编译线程相关
  
  - 需要使用 `-pthread`选项 链接pthread库

### 锁

- 锁变量保存锁在某一时刻的状态，要么可用，要么被占用。一个线程持有锁表示处于临界区。锁也称为互斥量

- 实现锁和评价锁的实现
  
  - 完成锁实现互斥访问的作用，即临界区保护
  
  - 公平性，多个线程阻塞在锁上，一旦开锁竞争是否是公平的。

- 中断控制
  
  - 在进入临界区之前将中断关闭，保证临界区代码不会被中断，从而保证原子的执行
    
    - 直接关闭中断实现的临界区不被中断打断有几个缺点
      
      1. 要求足够信任程序对中断的开关控制
      
      2. 不支持多处理器
      
      3. 会导致中断丢失

. 自旋锁

- 自旋锁实现
  
  - 原子操作：获取锁的旧值并改锁值（表示一直在拿锁），返回旧值，通过旧值判断是否有线程占有该锁。关键是这整个过程为一个原子操作，有硬件支持的test-and-set指令。测试旧值，设置新值。
    
    硬件也有支持compare-and-set指令，整个过程为原子操作，比较旧值是否为期望值，是的话进行值设置，不是为期望值是什么都不做，并返回真实旧值提供给调用值判断比较结果。
  
  - 自旋锁在单处理器上运行需要抢占式调度器，通过时钟中断一个线程，运行其他线程

- 自旋锁不提供任何公平保证，根据调度器来

- 自旋锁的性能：
  
  - 单处理器上性能开销比较大，一个线程持有锁后被其他线程抢占，其他阻塞在该锁上的线程每次要锁时需要自旋一个时间片然后在时钟中断到来时被其他线程抢占。
  
  - 多CPU上，线程数小于CPU数，保证了一个占有锁的线程不会被抢占而保证临界区很快进行完毕，性能大大提高，避免了多次自旋时间片。
